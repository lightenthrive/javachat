# 缓存概论

## 什么时候适合使用缓存？

下面的2中情况下，优化存储系统是无法有效提升性能的。

1. 需要经过复杂运算得出的数据

   例如需要展示有多少用户在线，如果使用数据库，每次都要执行 count 操作，展示量很大的话就对数据库造成了极大压力。

1. 读多写少的数据

   例如一个明星发布一条微博，可能有几千万人浏览，如果每次浏览都 select 一次的话，几千万的请求对数据库的压力非常大。

   缓存就是为了减轻存储系统的压力，将可重复使用的数据放到内存中，一次生成、多次使用。

## 缓存读写业务流程有什么影响？

## [缓存，究竟是淘汰，还是修改？](http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961313&idx=1&sn=60d74fdbc1fb1dae696e0f4997c09f21&chksm=bd2d023d8a5a8b2bba2f8a3807492771a442495d27323d8dbfae670508fd0c46780308a9280d&scene=21#wechat_redirect)

## 应该先操作数据库，还是操作缓存？

[Cache Aside Pattern](http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961349&idx=1&sn=59119a223f62d3740712ca0f62064f04&chksm=bd2d0dd98a5a84cf94d75e8e84ad7fe35fd040dfe02fe49db8dd64127c548aa194d2d169e149&scene=21#wechat_redirect)

**观点**：应该先操作数据库，再淘汰缓存

**原因**：否则，读写并发会导致数据不一致

[或许，应该先淘汰缓存？](http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961341&idx=1&sn=e27916b8e96bd771c72c055f1f53e5be&chksm=bd2d02218a5a8b37ecffd78d20b65501645ac07c7ba2eb65b7e501a3eb9de023febe63bfdb36&scene=21#wechat_redirect)

**观点**：应该先淘汰缓存，再操作数据库

**原因**：否则，原子性被破坏时，会导致数据不一致

先把缓存设置为空值，然后写入数据库，最后刷新缓存。

 不管先操作数据库，还是先操作缓存，都解决不了“写后立刻读，脏数据库入缓存”的问题。

### 什么是“写后立刻读，脏数据库入缓存”问题？

**答**：发生写请求后（不管是先操作DB，还是先淘汰Cache），在主从数据库同步完成之前，如果有读请求，都可能发生读Cache Miss，读从库把旧数据存入缓存的情况。此时怎么办呢？遂引出了下一篇文章。  

### [缓存与数据库不一致，怎么办？](http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961356&idx=1&sn=8fa6a57d128a3255a049bee868a7a917&chksm=bd2d0dd08a5a84c62c1ac1d90b9f4c11915c9e6780759d167da5343c43445759bce0f16de395&scene=21#wechat_redirect)

缓存与数据库的不一致，本质是由主从数据库延时引起的.

## [主从数据库不一致，怎么办？](http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961330&idx=1&sn=4bdbada3b26d4fc2fc505f7a0f2ad7c4&chksm=bd2d022e8a5a8b38e59f0dfffba7ca407fe8711644b3794832572dd822c665205bb820cdddf7&scene=21#wechat_redirect)

文章提出了三种优化方案，最后一个方案挺有意思，一个很巧妙的方法。

## 什么是穿透型缓存，什么是旁路型缓存？

## 什么时候用进程内缓存，什么时候用缓存服务？

## [缓存服务，你真的用对了么？](http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961307&idx=1&sn=2ea36d014299c7870a0b40575578469e&chksm=bd2d02078a5a8b111d0caa649ae93f050ee6d4168c43322c2cf8cd8387becdd9b78a7202daa0&scene=21#wechat_redirect)

## 缓存在微服务体系架构中的位置，以及设计原则？

## 缓存穿透，以及解决方案是什么？

指业务系统在缓存中没有查到数据，需要再次去存储系统查询。

通常有2种情况：

1. **存储数据不存在**

   被访问的数据确实不存在，存储系统中没有，那么缓存中肯定也没有。

   对于这类数据，每次都要查询缓存、查询存储系统，如果有人恶意大量访问一些不存在的数据，就会对系统产生严重影响。

   解决方案是：设置默认值到缓存中。对一定不存在的key进行过滤，bitmap布隆过滤器。

1. **缓存数据生成需要耗费时间或者资源**

   存储系统中存在数据，但生成缓存耗时耗资源，缓存失效后，访问压力就集中在存储系统了。

   例如商品分页，数据量巨大，不能都缓存起来，只能分页缓存，页数靠后的访问少，缓存就很容易过期消失，之后的访问需要计算、访问存储层，重新生成缓存。

   正常情况这类访问不会频繁，但如果爬虫遍历的时候，系统性能就可能出问题了。

   这种情况没有太好的解决方案，可以考虑：

- 识别爬虫，对ip限流或者把请求路由到独立的服务器；
- 做好监控，发现问题后及时处理，爬虫不是攻击，对系统的影响是逐步的，监控发现问题后有时间处理。

## 缓存雪崩，以及解决方案是什么？

当缓存过期被清除后，业务系统需要重新生成缓存，访问存储系统、计算。

高并发的系统中，在新缓存还未生成的这一小段时间内，可能会有上百个请求进来，他们发现缓存中没有，就都去生成缓存，从而对存储系统造成巨大压力，引发连锁反应，造成系统崩溃。

另外，当缓存服务器重启，或者同时失效，也会引发缓存雪崩。

解决方案：

1. 加锁同步更新

   对缓存更新操作进行加锁保护，保证只有一个线程能够进行缓存更新。

   对于分布式系统，可能有上百台服务器，即使每台服务器上只有一个更新线程，但总体数量大，同样会引发雪崩，需要使用分布式锁。

   也可以使用队列来控制写缓存的进程数量。

1. 后台异步更新

   缓存有效期设为永久，后台线程定时更新。

   需要考虑一个情况：当缓存内存不足时，会清理掉一些缓存数据，从被清理到下次更新缓存这段时间内，业务访问时读到的就是空。

   可以考虑当业务发现缓存失效后，加锁设置默认值，并且发送一个消息，通知后台线程进行更新。

   后台更新机制还适合做缓存预热。指系统上线后，定时触发了缓存加载，不用等待用户访问才加载。

1. 防止雪崩

   对不同的key，设置不同的过期时间。设置二级缓存，fail-over失效转移。

## 如何保证缓存中的数据都是热点数据？

通过过期时间、使用频率和最后使用时间，选择淘汰策略。

## 热点key怎么处理？

缓存中的个别数据可能是大热点，短时间内会被高频访问，虽然缓存服务器的性能好，但如果访问量过大也会带来性能压力。例如明星的某条微博被海量用户浏览。

解决方案：对缓存副本加前后缀，将请求哈希分散到多台机器上，减轻单体服务器压力。

需要注意：不同副本不要设置统一的过期时间，防止同时失效引起雪崩。可以设定一个过期时间范围，不同副本的过期时间指定范围内的随机值。


# 缓存算法

## 怎么实现一个简单lrumap ?

## 缓存的种类有哪些？

浏览器缓存，静态文件缓存，进程内本地缓存，分布式缓存。

## 分布式、集群环境中，缓存如何刷新，如何保持同步？

A、缓存如何刷新？1、定时刷新 2、主动刷新覆盖，每个缓存框架都有自带的刷新机制，或者说缓存失效机制，就拿Redis和 Ehcache举例， 他们都有自带的过期机制，另外主动刷新覆盖时，只需获取对应的key进行数据的覆盖即可。

B、缓存如何保持同步？ 这个redis有自带的集群同步机制，即复制功能，具体参考：基于Redis分布式缓存实现，Ehcache也有分布式缓存同步的配置，只需要配置不同服务器地址即可，参照：Ehcache分布式缓存同步。

## 缓存的过期策略和存在的缺点？

LRU 最近最少被使用的数据被淘汰，重点是最近，淘汰最晚访问的缓存。

缺点是：可能会因为一次冷数据的批量查询而误淘汰大量热点数据。

LFU 最少被使用，淘汰最少命中的缓存。

缺点是：新数据很容易被淘汰。

FIFO 先入先出，淘汰最先写入的缓存。

限制是：用于特定领域，如作业调度和消息队列。

# 进程内缓存

## [进程内缓存究竟怎么玩？](http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961296&idx=1&sn=883a46db0e4b4fe8bd2de5a370e3304e&chksm=bd2d020c8a5a8b1a2938b07da1a42648d562c559d573b5700e48ea5318dac3ee246b2e6ce908&scene=21#wechat_redirect)

### 什么是进程内缓存？

将一些数据缓存在站点，或者服务的进程内，这就是进程内缓存。

 进程内缓存的实现载体，最简单的，可以是一个**带锁的Map**。又或者，可以使用**第三方库**，例如leveldb。

### 进程内缓存有什么好处和缺点？

与没有缓存相比，进程内缓存的好处是，数据读取不再需要访问后端，例如数据库。

与进程外缓存相比（例如redis/memcache），进程内缓存省去了网络开销，所以一来节省了内网带宽，二来响应时延会更低。

缺点是：如果数据缓存在站点和服务的多个节点内，数据存了多份，一致性比较难保障。

### 如何保证进程内缓存的数据一致性？

**第一种方案**，可以通过单节点通知其他节点。如上图：写请求发生在server1，在修改完自己内存数据与数据库中的数据之后，可以主动通知其他server节点，也修改内存的数据。

 这种方案的**缺点**是：同一功能的一个集群的多个节点，相互耦合在一起，特别是节点较多时，网状连接关系极其复杂。

**第二种方案**，可以通过MQ通知其他节点。如上图，写请求发生在server1，在修改完自己内存数据与数据库中的数据之后，给MQ发布数据变化通知，其他server节点订阅MQ消息，也修改内存数据。

 这种方案虽然解除了节点之间的耦合，但引入了MQ，使得系统更加复杂。

**第三种方案**，为了避免耦合，降低复杂性，干脆放弃了“实时一致性”，每个节点启动一个timer，定时从后端拉取最新的数据，更新内存缓存。在有节点更新后端数据，而其他节点通过timer更新数据之间，会读到脏数据。

### 为什么不能频繁使用进程内缓存？

**分层架构设计，有一条准则**：站点层、服务层要做到无数据无状态，这样才能任意的加节点水平扩展，数据和状态尽量存储到后端的数据存储服务，例如数据库服务或者缓存服务。

 可以看到，站点与服务的**进程内缓存**，实际上违背了分层架构设计的无状态准则，故一般不推荐使用。

### 什么时候可以使用进程内缓存？

**答**：以下情况，可以考虑使用进程内缓存。

**情况一**，只读数据，可以考虑在进程启动时加载到内存。

画外音：此时也可以把数据加载到redis / memcache，进程外缓存服务也能解决这类问题。

 **情况二**，极其高并发的，如果透传后端压力极大的场景，可以考虑使用进程内缓存。

例如，秒杀业务，并发量极高，需要站点层挡住流量，可以使用内存缓存。

 **情况三**，一定程度上允许数据不一致业务。

例如，有一些计数场景，运营场景，页面对数据一致性要求较低，可以考虑使用进程内页面缓存。

## ehcache的特点，适用场景，以及存在的问题是什么？

Ehcache 的线程模型适合高并发应用，可以构成集群，简单快速。内存磁盘两层缓存，数据在虚拟机重启时可以写入和读取磁盘。

适用场景是：更新少，否则就不需要用缓存了。并发要求不严格，因为不能实时同步。对数据一致性要求不高，否则用集中式缓存如memcache，redis等，并且可以把ehcache用作二级缓存。

存在的问题有：缓存漂移，更新某节点后其他节点不动弹，就需要通过轮询或者消息队列来通知。数据库瓶颈，同时更新多个节点的缓存，数据库开销大，就需要使用数据库集群或者缓存分发。

## guava cache的特点和适用场景是什么？

guava cache是一个全内存的本地缓存，线程安全，功能完善，具有ConcurrentHashMap所不具备的缓存过期和数据的加载/刷新等功能。通过CacheLoader和Callable 回调创建，具体是使用CacheBuilder的静态方法建造Cache接口的对象，构造(使用)时传入CacheLoader(Callable)匿名对象。

适用场景是：消耗少量本地内存提升性能，更新锁定(refreshAfterWrite配置项，刷新时只允许一个请求回源，其他阻塞固定时间，没有新值就返回旧值)。

可以基于数据大小(maximumSize配置)，过期时间(expireAfterAccess/expireAfterWrite)和引用来删除，也可以主动删除(invalidate)。

# 分布式缓存

## redis不同于memcached的优点是什么？

memcached的值都是简单字符串，值的大小不超过1M。redis类型丰富，值的大小可以达到1G,字符串512M。另外，redis的速度快，可以持久化，支持aof和rdb的数据备份，有自定义的vm。

## memcache和redis分别适合什么场景？

## [到底选redis还是memcache，看看源码怎么说？](http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961272&idx=1&sn=79ad515b013b0ffc33324db86ba0f834&chksm=bd2d02648a5a8b728db094312f55574ec521b30e3de8aacf1d2d948a3ac24dbf30e835089fa7&scene=21#wechat_redirect)

## [到底选redis还是memcache，面试官究竟想考察啥？](http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961269&idx=1&sn=ea447397423a2ad9d9f44ad51f0bed5e&chksm=bd2d02698a5a8b7f966f77c0283124e7d7dee42cc604b418b57ba4ff15e583fe2873a356dc31&scene=21#wechat_redirect)

# 架构设计



## 如何实现超高并发的无锁缓存？

在【超高并发】，【写多读少】，【定长value】的【业务缓存】场景下：

1）可以通过**水平拆分**来降低锁冲突

2）可以通过**Map转Array**的方式来最小化锁冲突，一条记录一个锁

3）可以**把锁去掉**，最大化并发，但带来的数据完整性的破坏

4）可以通过签名的方式保证数据的完整性，实现**无锁缓存**

### **写多读少的业务场景**

大部分请求是对数据进行修改，少部分请求对数据进行读取。

- 滴滴打车，某个司机**地理位置信息**可能每几秒钟有一个修改，以及司机地理位置的读取。
- **统计计数的变化**，某个url的访问次数，用户某个行为的反作弊计数值在不停的变以及只有少数时刻会读取这类数据。

这种此等实现，一般是一个**定长key，定长value**的缓存Map结构来存储司机的信息，或者某个类型的计数。

这个Map存储了所有信息，当并发读写访问时，它作为临界资源，在读写之前，如果不使用ConcurrentHashMap，一般要进行加锁操作：

```java
void SetDriverInfo(long driver_id, DriverInfoinfo){
         WriteLock (m_lock);
         Map<driver_id>= info;
         UnWriteLock(m_lock);
}
 
DriverInfo GetDriverInfo(long driver_id){
         DriverInfo t;
         ReadLock(m_lock);
         t= Map<driver_id>;
         UnReadLock(m_lock);
         return t;
}
```

**【并发锁瓶颈】**

假设滴滴有100w司机同时在线，每个司机没5秒更新一次经纬度状态，那么每秒就有20w次写并发操作。假设滴滴日订单1000w个，平均每秒大概也有300个下单，对应到查询并发量，可能是1000级别的并发读操作。

上述实现方案没有任何问题，但**在并发量很大的时候（每秒20w写，1k读），锁m_lock会成为潜在瓶颈，**

#### **并发锁的拆分**

- **水平切分+锁粒度优化**

类似于数据库的“库锁”，可以水平拆分成多个Map。

```java
void SetDriverInfo(long driver_id, DriverInfoinfo){
         i= driver_id % N; // 水平拆分成N份，N个Map，N个锁
         WriteLock (m_lock [i]);  //锁第i把锁
         Map[i]<driver_id>= info;  // 操作第i个Map
         UnWriteLock (m_lock[i]); // 解锁第i把锁
}
```

库锁按照访问拆分成多个，变成锁的集群。

- **MAP变Array+最细锁粒度优化**

假设driver_id是递增生成的，并且缓存的内存比较大，是可以把Map优化成Array，而不是拆分成N个Map，是有可能把锁的粒度细化到最细的（每个记录一个锁）。

```java
void SetDriverInfo(long driver_id, DriverInfoinfo){
         index= driver_id;
         WriteLock (m_lock [index]);  //超级大内存，一条记录一个锁，锁行锁
         Array[index]= info; //driver_id就是Array下标
         UnWriteLock (m_lock[index]); // 解锁行锁
}
```

锁冲突减少了，数量增多了。数据量小的时候，可以对连接池的连接线程加锁。数据量大的时候，就不能对每行记录或者类型加锁。

- ###### **把锁去掉，变成无锁缓存**

利用数组索引的特性，实现行级分段锁。

```
void AddCountByType(long type /*, int count*/){
	//不加锁
    Array[type]++; // 计数++
    //Array[type] += count; // 计数增加count
}
```

如果这个缓存不加锁，当然可以达到最高的并发，但是多线程对缓存中同一块定长数据进行操作时，各写入一部分，有可能出现不一致的数据块，这个方案为了提高性能，牺牲了一致性。在读取计数时，获取到了错误的数据，是不能接受的（作为缓存，允许cache miss，却不允许读脏数据）。

**【数据完整性问题】**

并发写入的数据分别是value1和value2，读出的数据是value-unexpected，数据的篡改，这本质上是一个数据完整性的问题。**通常如何保证数据的完整性呢？**

**例子1**：运维使用md5保证，从中控机分发到上线机上的二进制没有被篡改。

**例子2**：即时通讯系统，消息带有签名，接受方校验消息签名，保证收到的消息，就是发送方发送的消息。

#### 数据签名

“签名”是一种常见的保证数据完整性的常见方案。

每一个值，都同时写入定长签名，比如CRC校验。读取数据时，要验证签名，不一致就返回null。



缓存失效会引发什么雪崩？
缓存是否需要保证高可用？如何保证高可用？
缓存如何保证与数据库中的数据一致性？
缓存如何保证无限量的扩展性？

## [feed流，单聊群聊，系统通知，状态同步，到底是推还是拉？](https://mp.weixin.qq.com/s/54yEWWet9mFztv1fO_GTqQ)

**一、feed流**

可以理解为一个发布订阅业务，典型业务是微博（朋友圈）。你关注了姚晨的微博，姚晨发布了消息，你的主页能看到她最新发布的消息，这个场景是推送，还是拉取呢？

*画外音：微博是弱关系，关注无需对方同意，粉丝可以无上限；朋友圈是强关系，好友需要对方同意，好友个数有上线。*

如果**推送**，姚晨发布消息的时候，要把消息ID投递到所有粉丝的主页消息队列里，推送量巨大。

如果**拉取**，一来主页消息无法实时更新，二来每次刷新动作非常复杂：

1. 拉取你关注人的list<user_id>
1. 拉取这些人的消息list<msg_id>
1. 对于这些人的这些消息进行rank处理，例如按照时间排序
1. 还无法对主页进行缓存，因为只要有关注人发布消息，主页内容就会变化
1. 还得考虑“不看谁的消息”，以及“消息不给谁看”
1. ...

是不是觉得有点烦？如果你是架构师，你会怎么做？

**二、聊天消息**

聊天消息又分为**单聊**和**群聊**，典型的业务是微信。和朋友小窗沟通是单聊，群内扯淡是群聊。

**单聊**，很容易想到是服务器推送，但浏览器里的聊天工具JS只能使用http式的request - response协议，又能不能保证消息的实时性呢？

**群聊**，一个群500个人，有人在线，有人离线，到底是推送，还是拉取呢？

如果是**推送**，1条消息将转变为500条消息，系统压力会异常之大。

如果是**拉取**，消息的实时性又该如何保障呢？

还有一个坑爹的需求，**“钉钉”的群聊天消息“已读回执”**，这个需求简单描述是：对于每一条你发出的每一群消息，你能够看到，多少人已读，多少人未读。这个群消息已读回执，猜猜看，又是怎么实现的呢？

**三、系统通知**

系统消息听上去比较泛，典型的业务是QQ的**登录广告弹窗**，以及登录后的右下角**广告提示**。

- QQ每天首次登录后的新闻弹窗

拉取？第二次登录却又没有。

- QQ运行过程中的QQ弹窗广告

推送？一次推送几千万条，会不会系统抖动？

或许，真实的实现方式或许与我们想的并不一样。

**四、状态同步**

玩桌面QQ时，收到过“你的好友XXOO登录了”的弹窗提示么？这是一个好友登录/登出**状态的客户端同步**。同理，群有500人，每个群友的在线/不在线状态又是怎么实现同步的呢？

推送？那一个用户登录退出都要推送N个好友？M个群友？

拉取？如何保证好友状态，群友状态的实时性？

*画外音：好友/群友状态一致性是非常复杂的，移动的时代，索性引入“一律在线”的概念，微信的好友就不存在所谓“头像亮”和“头像灰”的概念了，客户端状态同步这一块复杂性有所降低。*